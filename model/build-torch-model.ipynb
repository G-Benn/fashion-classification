{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentation using PyTorch to build a fashion outfit classifier\n",
    "This will (likely) be converted to a script at the end to prevent any Jupyter overhead, but we'll see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x20053cd9278>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import standard PyTorch modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter # TensorBoard support\n",
    "\n",
    "# import torchvision module to handle image manipulation\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# calculate train time, writing train data to files etc.\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from collections  import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)     # On by default, leave it here for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use standard FashionMNIST dataset\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root = '../data',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()                                 \n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ../data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the structure given in the tutorial is given to be very rigid - since we're dealing with fixed-resolution images and various convolves + poolings I'll need to keep the structure math correct. I'll play around with it and see if there's way I can improve it and why it might be working better (or most likely - worse). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use standard FashionMNIST dataset\n",
    "test_set = torchvision.datasets.FashionMNIST(\n",
    "    root = '../data',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()                                 \n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ../data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the neural network, expand on top of nn.Module\n",
    "# Base network given by the tutorial\n",
    "class Network(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    # define layers\n",
    "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "\n",
    "    self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "    self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "    self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "  # define forward function\n",
    "  def forward(self, t):\n",
    "    # conv 1\n",
    "    t = self.conv1(t) # transform the given tensor on the 1st convolutional layer\n",
    "    t = F.relu(t) # compute the activation function on the tensor\n",
    "    t = F.max_pool2d(t, kernel_size=2, stride=2) # pool the layer (it's now 1/2 the size it was (28-4 in each direction))\n",
    "\n",
    "    # conv 2\n",
    "    t = self.conv2(t) # repeat above\n",
    "    t = F.relu(t)\n",
    "    t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "    # fc1\n",
    "    t = t.reshape(-1, 12*4*4) # Flatten out the final pooling layer \n",
    "    t = self.fc1(t)\n",
    "    t = F.relu(t)\n",
    "\n",
    "    # fc2\n",
    "    t = self.fc2(t)\n",
    "    t = F.relu(t)\n",
    "\n",
    "    # output\n",
    "    t = self.out(t)\n",
    "    # don't need softmax here since we'll use cross-entropy as activation.\n",
    "\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some hyperparameter tuning\n",
    "# put all hyper params into a OrderedDict, easily expandable\n",
    "params = OrderedDict(\n",
    "    lr = [.01, .005, .001, .0005],\n",
    "    batch_size = [100, 250, 500, 1000],\n",
    "    shuffle = [True, False],\n",
    "    weight_decay = [0, 0.1]\n",
    ")\n",
    "epochs = 50\n",
    "\n",
    "# Read in the hyper-parameters and return a Run namedtuple containing all the \n",
    "# combinations of hyper-parameters\n",
    "class RunBuilder():\n",
    "  @staticmethod\n",
    "  def get_runs(params):\n",
    "\n",
    "    Run = namedtuple('Run', params.keys())\n",
    "\n",
    "    runs = []\n",
    "    for v in product(*params.values()):\n",
    "      runs.append(Run(*v))\n",
    "    \n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper class, help track loss, accuracy, epoch time, run time, \n",
    "# hyper-parameters etc. Also record to TensorBoard and write into csv, json\n",
    "class RunManager():\n",
    "    def __init__(self):\n",
    "\n",
    "        # tracking every epoch count, loss, accuracy, time\n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "\n",
    "        #Testing parameters\n",
    "        self.epoch_loss_test = 0\n",
    "        self.epoch_num_correct_test = 0\n",
    "        self.test_score_time = 0\n",
    "\n",
    "        # tracking every run count, run data, hyper-params used, time\n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "\n",
    "        # record model, loader and TensorBoard \n",
    "        self.network = None\n",
    "        self.loader = None\n",
    "        self.tb = None\n",
    "\n",
    "    # record the count, hyper-param, model, loader of each run\n",
    "    # record sample images and network graph to TensorBoard  \n",
    "    def begin_run(self, run, network, loader):\n",
    "\n",
    "        self.run_start_time = time.time()\n",
    "\n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "\n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment=f'-{run}')\n",
    "\n",
    "        images, labels = next(iter(self.loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "        self.tb.add_image('images', grid)\n",
    "        self.tb.add_graph(self.network, images)\n",
    "\n",
    "    # when run ends, close TensorBoard, zero epoch count\n",
    "    def end_run(self):\n",
    "        self.save_run()\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0\n",
    "\n",
    "\n",
    "    def save_run(self):\n",
    "        path = f\"./saved_models/model-{self.run_count}.pth\"\n",
    "        print(f\"saving model to {path}\")\n",
    "        torch.save(self.network.state_dict(), path)\n",
    "\n",
    "    # zero epoch count, loss, accuracy, \n",
    "    def begin_epoch(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "\n",
    "        #Testing parameters\n",
    "        self.epoch_loss_test = 0\n",
    "        self.epoch_num_correct_test = 0\n",
    "        self.test_score_time = 0    \n",
    "\n",
    "    # \n",
    "    def end_epoch(self):\n",
    "        # calculate epoch duration and run duration(accumulate)\n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "\n",
    "        # record epoch loss and accuracy\n",
    "        loss = self.epoch_loss / len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct / len(self.loader.dataset)    \n",
    "\n",
    "        # Record results on Testing parameters\n",
    "        test_loss = self.epoch_loss_test / 10000\n",
    "        test_accuracy = self.epoch_num_correct_test / 10000\n",
    "\n",
    "\n",
    "        # Record epoch loss and accuracy to TensorBoard \n",
    "        self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
    "        self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
    "        self.tb.add_scalar('Test Loss', test_loss, self.epoch_count)\n",
    "        self.tb.add_scalar('Test Accuracy', test_accuracy, self.epoch_count)\n",
    "\n",
    "        # Record params to TensorBoard\n",
    "        for name, param in self.network.named_parameters():\n",
    "          self.tb.add_histogram(name, param, self.epoch_count)\n",
    "          self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
    "\n",
    "        # Write into 'results' (OrderedDict) for all run related data\n",
    "        results = OrderedDict()\n",
    "        results[\"run\"] = self.run_count\n",
    "        results[\"epoch\"] = self.epoch_count\n",
    "        results[\"loss\"] = loss\n",
    "        results[\"accuracy\"] = accuracy\n",
    "        results[\"test_loss\"] = test_loss\n",
    "        results[\"test_accuracy\"] = test_accuracy\n",
    "        results[\"test_score_time\"] = self.test_score_time / 10000 # time per image to score, in seconds I think\n",
    "        results[\"epoch duration\"] = epoch_duration\n",
    "        results[\"run duration\"] = run_duration\n",
    "\n",
    "        # Record hyper-params into 'results'\n",
    "        for k,v in self.run_params._asdict().items(): results[k] = v\n",
    "        self.run_data.append(results)\n",
    "        df = pd.DataFrame.from_dict(self.run_data, orient = 'columns')\n",
    "\n",
    "        # display epoch information and show progress\n",
    "        clear_output(wait=True)\n",
    "        display(df)\n",
    "\n",
    "    # accumulate loss of batch into entire epoch loss\n",
    "    def track_loss(self, loss):\n",
    "        # multiply batch size so variety of batch sizes can be compared\n",
    "        self.epoch_loss += loss.item() * self.loader.batch_size\n",
    "\n",
    "    # accumulate number of corrects of batch into entire epoch num_correct\n",
    "    def track_num_correct(self, preds, labels):\n",
    "        self.epoch_num_correct += self._get_num_correct(preds, labels)\n",
    "\n",
    "    # accumulate loss of batch into entire epoch loss\n",
    "    def track_loss_test(self, loss):\n",
    "        # multiply batch size so variety of batch sizes can be compared\n",
    "        self.epoch_loss_test += loss.item() * 10000 # test loaded is a batch of 10000, so known factor. extra param?\n",
    "\n",
    "    # accumulate number of corrects of batch into entire epoch num_correct\n",
    "    def track_num_correct_test(self, preds, labels):\n",
    "        self.epoch_num_correct_test += self._get_num_correct(preds, labels)\n",
    "\n",
    "    def track_score_time_test(self, start_time, end_time):\n",
    "        self.test_score_time = end_time - start_time\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _get_num_correct(self, preds, labels):\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "    # save end results of all runs into csv, json for further analysis\n",
    "    def save(self, fileName):\n",
    "\n",
    "        pd.DataFrame.from_dict(\n",
    "            self.run_data, \n",
    "            orient = 'columns',\n",
    "        ).to_csv(f'{fileName}.csv')\n",
    "\n",
    "        with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.run_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_score_time</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571084</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.474609</td>\n",
       "      <td>0.8240</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>14.985999</td>\n",
       "      <td>15.112995</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.384029</td>\n",
       "      <td>0.858733</td>\n",
       "      <td>0.422084</td>\n",
       "      <td>0.8468</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>15.129178</td>\n",
       "      <td>30.306175</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.357485</td>\n",
       "      <td>0.868433</td>\n",
       "      <td>0.410488</td>\n",
       "      <td>0.8483</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>14.587510</td>\n",
       "      <td>44.956686</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.345991</td>\n",
       "      <td>0.873317</td>\n",
       "      <td>0.413018</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>15.190000</td>\n",
       "      <td>60.214687</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.328996</td>\n",
       "      <td>0.878567</td>\n",
       "      <td>0.421892</td>\n",
       "      <td>0.8592</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>14.561999</td>\n",
       "      <td>74.835686</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>64</td>\n",
       "      <td>46</td>\n",
       "      <td>2.302600</td>\n",
       "      <td>0.096200</td>\n",
       "      <td>2.302518</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>29.868891</td>\n",
       "      <td>974.734261</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>64</td>\n",
       "      <td>47</td>\n",
       "      <td>2.302600</td>\n",
       "      <td>0.096200</td>\n",
       "      <td>2.302518</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>29.875001</td>\n",
       "      <td>1004.670263</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>2.302600</td>\n",
       "      <td>0.096200</td>\n",
       "      <td>2.302518</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>29.505000</td>\n",
       "      <td>1034.232261</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>64</td>\n",
       "      <td>49</td>\n",
       "      <td>2.302600</td>\n",
       "      <td>0.096200</td>\n",
       "      <td>2.302518</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>29.637001</td>\n",
       "      <td>1063.929262</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>2.302600</td>\n",
       "      <td>0.096200</td>\n",
       "      <td>2.302518</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>28.902997</td>\n",
       "      <td>1092.890263</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      run  epoch      loss  accuracy  test_loss  test_accuracy  \\\n",
       "0       1      1  0.571084  0.781250   0.474609         0.8240   \n",
       "1       1      2  0.384029  0.858733   0.422084         0.8468   \n",
       "2       1      3  0.357485  0.868433   0.410488         0.8483   \n",
       "3       1      4  0.345991  0.873317   0.413018         0.8531   \n",
       "4       1      5  0.328996  0.878567   0.421892         0.8592   \n",
       "...   ...    ...       ...       ...        ...            ...   \n",
       "3195   64     46  2.302600  0.096200   2.302518         0.1000   \n",
       "3196   64     47  2.302600  0.096200   2.302518         0.1000   \n",
       "3197   64     48  2.302600  0.096200   2.302518         0.1000   \n",
       "3198   64     49  2.302600  0.096200   2.302518         0.1000   \n",
       "3199   64     50  2.302600  0.096200   2.302518         0.1000   \n",
       "\n",
       "      test_score_time  epoch duration  run duration      lr  batch_size  \\\n",
       "0            0.000035       14.985999     15.112995  0.0100         100   \n",
       "1            0.000034       15.129178     30.306175  0.0100         100   \n",
       "2            0.000034       14.587510     44.956686  0.0100         100   \n",
       "3            0.000034       15.190000     60.214687  0.0100         100   \n",
       "4            0.000035       14.561999     74.835686  0.0100         100   \n",
       "...               ...             ...           ...     ...         ...   \n",
       "3195         0.000261       29.868891    974.734261  0.0005        1000   \n",
       "3196         0.000252       29.875001   1004.670263  0.0005        1000   \n",
       "3197         0.000257       29.505000   1034.232261  0.0005        1000   \n",
       "3198         0.000262       29.637001   1063.929262  0.0005        1000   \n",
       "3199         0.000225       28.902997   1092.890263  0.0005        1000   \n",
       "\n",
       "      shuffle  weight_decay  \n",
       "0        True           0.0  \n",
       "1        True           0.0  \n",
       "2        True           0.0  \n",
       "3        True           0.0  \n",
       "4        True           0.0  \n",
       "...       ...           ...  \n",
       "3195    False           0.1  \n",
       "3196    False           0.1  \n",
       "3197    False           0.1  \n",
       "3198    False           0.1  \n",
       "3199    False           0.1  \n",
       "\n",
       "[3200 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This code is all from the tutorial, but I can probably improve on it by getting the runs to happen in parallel - test that\n",
    "m = RunManager()\n",
    "\n",
    "print(f\"Total number of runs: {len(RunBuilder.get_runs(params))}\")\n",
    "print(f\"Total number of epochs: {epochs*len(RunBuilder.get_runs(params))}\")\n",
    "print(f\"Time required @ 15s / epoch: {15*epochs*len(RunBuilder.get_runs(params))} seconds, {(1/240)*epochs*len(RunBuilder.get_runs(params))} hours\")\n",
    "\n",
    "# get all runs from params using RunBuilder class\n",
    "for run in RunBuilder.get_runs(params):\n",
    "\n",
    "    # if params changes, following line of code should reflect the changes too\n",
    "    network = Network()\n",
    "    loader = torch.utils.data.DataLoader(train_set, batch_size = run.batch_size)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=run.lr, weight_decay = run.weight_decay)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size = len(test_set))\n",
    "    \n",
    "    m.begin_run(run, network, loader)\n",
    "    for epoch in range(epochs):\n",
    "      \n",
    "      m.begin_epoch()\n",
    "    \n",
    "      for batch in loader:\n",
    "        \n",
    "        images = batch[0]\n",
    "        labels = batch[1]\n",
    "        preds = network(images)\n",
    "        loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        m.track_loss(loss)\n",
    "        m.track_num_correct(preds, labels)\n",
    "      \n",
    "      for batch in test_loader:\n",
    "        test_images = batch[0]\n",
    "        test_labels = batch[1]\n",
    "        score_start_time = time.time()\n",
    "        test_preds = network(test_images)\n",
    "        score_end_time = time.time()\n",
    "        test_loss = F.cross_entropy(test_preds, test_labels)\n",
    "        \n",
    "        m.track_loss_test(test_loss)\n",
    "        m.track_num_correct_test(test_preds, test_labels)\n",
    "        m.track_score_time_test(score_start_time, score_end_time)\n",
    "        \n",
    "    \n",
    "      m.end_epoch()\n",
    "    m.end_run()\n",
    "\n",
    "# when all runs are done, save results to files\n",
    "m.save('results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm unsure if using this service is necessary since this is a windows machine and not colab, but giving it a go anyways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a subprocess that starts tensorboard, but don't wait for it to exit before exiting\n",
    "import subprocess\n",
    "\n",
    "LOG_DIR = './runs'\n",
    "cmd = f\"tensorboard --logdir {LOG_DIR} --host 0.0.0.0 --port 6006 &\"\n",
    "tb_proc = subprocess.Popen(cmd, shell = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tb_proc.kill() # End the Tensorboard process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've run everything (and can look at it if desired), pick the parameters that result in the lowest test loss and/or highest test accuracy and rerun it for however many epochs it takes to 'max out'. If the loss is still decreasing > 0.01 for a step, double the current max number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_score_time</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571084</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.474609</td>\n",
       "      <td>0.8240</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>14.985999</td>\n",
       "      <td>15.112995</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.384029</td>\n",
       "      <td>0.858733</td>\n",
       "      <td>0.422084</td>\n",
       "      <td>0.8468</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>15.129178</td>\n",
       "      <td>30.306175</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.357485</td>\n",
       "      <td>0.868433</td>\n",
       "      <td>0.410488</td>\n",
       "      <td>0.8483</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>14.587510</td>\n",
       "      <td>44.956686</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.345991</td>\n",
       "      <td>0.873317</td>\n",
       "      <td>0.413018</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>15.190000</td>\n",
       "      <td>60.214687</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.328996</td>\n",
       "      <td>0.878567</td>\n",
       "      <td>0.421892</td>\n",
       "      <td>0.8592</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>14.561999</td>\n",
       "      <td>74.835686</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.322750</td>\n",
       "      <td>0.879883</td>\n",
       "      <td>0.387615</td>\n",
       "      <td>0.8627</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>14.572000</td>\n",
       "      <td>89.470686</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.315733</td>\n",
       "      <td>0.882533</td>\n",
       "      <td>0.406133</td>\n",
       "      <td>0.8576</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>14.516999</td>\n",
       "      <td>104.052686</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.308738</td>\n",
       "      <td>0.885250</td>\n",
       "      <td>0.368054</td>\n",
       "      <td>0.8733</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>14.639998</td>\n",
       "      <td>118.762685</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.302874</td>\n",
       "      <td>0.887483</td>\n",
       "      <td>0.380699</td>\n",
       "      <td>0.8696</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>14.466998</td>\n",
       "      <td>133.292686</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.300301</td>\n",
       "      <td>0.888233</td>\n",
       "      <td>0.377599</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>14.837000</td>\n",
       "      <td>148.195685</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run  epoch      loss  accuracy  test_loss  test_accuracy  test_score_time  \\\n",
       "0    1      1  0.571084  0.781250   0.474609         0.8240         0.000035   \n",
       "1    1      2  0.384029  0.858733   0.422084         0.8468         0.000034   \n",
       "2    1      3  0.357485  0.868433   0.410488         0.8483         0.000034   \n",
       "3    1      4  0.345991  0.873317   0.413018         0.8531         0.000034   \n",
       "4    1      5  0.328996  0.878567   0.421892         0.8592         0.000035   \n",
       "5    1      6  0.322750  0.879883   0.387615         0.8627         0.000039   \n",
       "6    1      7  0.315733  0.882533   0.406133         0.8576         0.000035   \n",
       "7    1      8  0.308738  0.885250   0.368054         0.8733         0.000036   \n",
       "8    1      9  0.302874  0.887483   0.380699         0.8696         0.000034   \n",
       "9    1     10  0.300301  0.888233   0.377599         0.8667         0.000034   \n",
       "\n",
       "   epoch duration  run duration    lr  batch_size  shuffle  weight_decay  \n",
       "0       14.985999     15.112995  0.01         100     True           0.0  \n",
       "1       15.129178     30.306175  0.01         100     True           0.0  \n",
       "2       14.587510     44.956686  0.01         100     True           0.0  \n",
       "3       15.190000     60.214687  0.01         100     True           0.0  \n",
       "4       14.561999     74.835686  0.01         100     True           0.0  \n",
       "5       14.572000     89.470686  0.01         100     True           0.0  \n",
       "6       14.516999    104.052686  0.01         100     True           0.0  \n",
       "7       14.639998    118.762685  0.01         100     True           0.0  \n",
       "8       14.466998    133.292686  0.01         100     True           0.0  \n",
       "9       14.837000    148.195685  0.01         100     True           0.0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in the results\n",
    "result_df = pd.read_json('results.json')\n",
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': {'run': 33, 'val': 0.9449666666666661},\n",
       " 'test_accuracy': {'run': 41, 'val': 0.8955000000000001},\n",
       " 'loss': {'run': 33, 'val': 0.14635570105165202},\n",
       " 'test_loss': {'run': 41, 'val': 0.30875414609909},\n",
       " 'test_score_time': {'run': 56, 'val': 3.389716148376465e-05}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_epoch = max(result_df['epoch']) # same for everything so this is safe\n",
    "trim_df = result_df[result_df['epoch']==max_epoch].reset_index(drop=True)\n",
    "\n",
    "max_factors = ['accuracy','test_accuracy']\n",
    "min_factors = ['loss', 'test_loss', 'test_score_time']\n",
    "best_factors = {}\n",
    "for factor in max_factors:\n",
    "    max_val = trim_df[factor].max()\n",
    "    max_run = trim_df.iloc[trim_df[factor].idxmax()]['run']\n",
    "    best_factors[factor] = {'run':max_run, 'val':max_val}\n",
    "    \n",
    "for factor in min_factors:\n",
    "    min_val = trim_df[factor].min()\n",
    "    min_run = trim_df.iloc[trim_df[factor].idxmin()]['run']\n",
    "    best_factors[factor] = {'run':min_run, 'val':min_val}\n",
    "best_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than decide what run is best sight-unseen, pick one by hand based on a number of factors:  \n",
    "- Best training accuracy / loss\n",
    "- Best test accuracy / loss (generalization)\n",
    "- Was the loss still decreasing?\n",
    "- similarity of parameters\n",
    "This will be used to create a new run that will take the best parameters and save it off to use in the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a single model run, extract a) parameters of the run and b) the best factors\n",
    "def best_features(df):\n",
    "    # Assume some column names here\n",
    "    params = ['lr', 'batch_size', 'shuffle', 'weight_decay']\n",
    "    min_factors = ['loss', 'test_loss']\n",
    "    max_factors = ['accuracy','test_accuracy']\n",
    "    \n",
    "    result_dict = OrderedDict()\n",
    "    \n",
    "    for param in params:\n",
    "        result_dict[param] = df[param].min()\n",
    "    \n",
    "    for f in min_factors:\n",
    "        result_dict[f] = df[f].min()\n",
    "        if df[f].argmin() != df['epoch'].max():\n",
    "            print(f\"{f} regressed during the run!\")\n",
    "            print(f\"{df[f].argmin()} - {df['epoch'].max()}\")\n",
    "            \n",
    "    for f in max_factors:\n",
    "        result_dict[f] = df[f].max()\n",
    "        if df[f].argmax() != df['epoch'].max():\n",
    "            print(f\"{f} regressed during the run!\")\n",
    "            print(f\"{df[f].argmax()} - {df['epoch'].max()}\")\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss regressed during the run!\n",
      "49 - 50\n",
      "test_loss regressed during the run!\n",
      "18 - 50\n",
      "accuracy regressed during the run!\n",
      "49 - 50\n",
      "test_accuracy regressed during the run!\n",
      "15 - 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('lr', 0.001),\n",
       "             ('batch_size', 100),\n",
       "             ('shuffle', True),\n",
       "             ('weight_decay', 0.0),\n",
       "             ('loss', 0.14635570105165202),\n",
       "             ('test_loss', 0.319693833589553),\n",
       "             ('accuracy', 0.9449666666666661),\n",
       "             ('test_accuracy', 0.8869)])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_train = 33 # Based on the above\n",
    "best_train_features = best_features(result_df[result_df['run']==best_train])\n",
    "best_train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_score_time</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799589</td>\n",
       "      <td>0.697000</td>\n",
       "      <td>0.628467</td>\n",
       "      <td>0.7633</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>14.372286</td>\n",
       "      <td>14.491285</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>0.542897</td>\n",
       "      <td>0.793600</td>\n",
       "      <td>0.548165</td>\n",
       "      <td>0.8031</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>14.827357</td>\n",
       "      <td>29.400642</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>0.468001</td>\n",
       "      <td>0.829500</td>\n",
       "      <td>0.480319</td>\n",
       "      <td>0.8253</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>14.847250</td>\n",
       "      <td>44.329893</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>0.417899</td>\n",
       "      <td>0.848233</td>\n",
       "      <td>0.432517</td>\n",
       "      <td>0.8421</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>14.823349</td>\n",
       "      <td>59.239241</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>0.383459</td>\n",
       "      <td>0.860333</td>\n",
       "      <td>0.400061</td>\n",
       "      <td>0.8542</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>14.913375</td>\n",
       "      <td>74.236618</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>0.358139</td>\n",
       "      <td>0.868333</td>\n",
       "      <td>0.378867</td>\n",
       "      <td>0.8607</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>15.018525</td>\n",
       "      <td>89.343145</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>0.339560</td>\n",
       "      <td>0.874933</td>\n",
       "      <td>0.369679</td>\n",
       "      <td>0.8635</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>14.866960</td>\n",
       "      <td>104.289104</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>0.324624</td>\n",
       "      <td>0.880450</td>\n",
       "      <td>0.364067</td>\n",
       "      <td>0.8651</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.038766</td>\n",
       "      <td>119.411872</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>0.312916</td>\n",
       "      <td>0.884750</td>\n",
       "      <td>0.357986</td>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>14.934361</td>\n",
       "      <td>134.427235</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>0.302602</td>\n",
       "      <td>0.888367</td>\n",
       "      <td>0.353483</td>\n",
       "      <td>0.8699</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>15.069094</td>\n",
       "      <td>149.583329</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>0.293147</td>\n",
       "      <td>0.891617</td>\n",
       "      <td>0.346880</td>\n",
       "      <td>0.8734</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>14.937296</td>\n",
       "      <td>164.598628</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>0.284506</td>\n",
       "      <td>0.894583</td>\n",
       "      <td>0.343232</td>\n",
       "      <td>0.8755</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>14.970677</td>\n",
       "      <td>179.651307</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>0.277258</td>\n",
       "      <td>0.897233</td>\n",
       "      <td>0.334198</td>\n",
       "      <td>0.8791</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>15.047991</td>\n",
       "      <td>194.779299</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>0.269657</td>\n",
       "      <td>0.899600</td>\n",
       "      <td>0.331246</td>\n",
       "      <td>0.8809</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>15.142693</td>\n",
       "      <td>210.004992</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>0.262970</td>\n",
       "      <td>0.902000</td>\n",
       "      <td>0.326813</td>\n",
       "      <td>0.8837</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>14.931635</td>\n",
       "      <td>225.022628</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>33</td>\n",
       "      <td>16</td>\n",
       "      <td>0.256555</td>\n",
       "      <td>0.904017</td>\n",
       "      <td>0.321746</td>\n",
       "      <td>0.8869</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.214333</td>\n",
       "      <td>240.319961</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>0.250767</td>\n",
       "      <td>0.906850</td>\n",
       "      <td>0.321442</td>\n",
       "      <td>0.8869</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.047065</td>\n",
       "      <td>255.453025</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>0.245078</td>\n",
       "      <td>0.908700</td>\n",
       "      <td>0.320948</td>\n",
       "      <td>0.8845</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.174681</td>\n",
       "      <td>270.715704</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>33</td>\n",
       "      <td>19</td>\n",
       "      <td>0.239751</td>\n",
       "      <td>0.910500</td>\n",
       "      <td>0.319694</td>\n",
       "      <td>0.8841</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.059581</td>\n",
       "      <td>285.860286</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>0.234728</td>\n",
       "      <td>0.912317</td>\n",
       "      <td>0.322230</td>\n",
       "      <td>0.8854</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>15.083117</td>\n",
       "      <td>301.031404</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>33</td>\n",
       "      <td>21</td>\n",
       "      <td>0.230081</td>\n",
       "      <td>0.913650</td>\n",
       "      <td>0.319822</td>\n",
       "      <td>0.8856</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.473320</td>\n",
       "      <td>316.587726</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>0.225892</td>\n",
       "      <td>0.915250</td>\n",
       "      <td>0.322645</td>\n",
       "      <td>0.8857</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>15.263279</td>\n",
       "      <td>331.932008</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>33</td>\n",
       "      <td>23</td>\n",
       "      <td>0.221577</td>\n",
       "      <td>0.916733</td>\n",
       "      <td>0.323192</td>\n",
       "      <td>0.8848</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>15.136012</td>\n",
       "      <td>347.151020</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>0.216738</td>\n",
       "      <td>0.918800</td>\n",
       "      <td>0.332345</td>\n",
       "      <td>0.8841</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.240387</td>\n",
       "      <td>362.473406</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>0.212468</td>\n",
       "      <td>0.919967</td>\n",
       "      <td>0.334772</td>\n",
       "      <td>0.8845</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.076246</td>\n",
       "      <td>377.635655</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>0.208588</td>\n",
       "      <td>0.921000</td>\n",
       "      <td>0.338064</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.142278</td>\n",
       "      <td>392.864934</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>33</td>\n",
       "      <td>27</td>\n",
       "      <td>0.204960</td>\n",
       "      <td>0.922400</td>\n",
       "      <td>0.342642</td>\n",
       "      <td>0.8849</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>15.041318</td>\n",
       "      <td>407.993253</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>33</td>\n",
       "      <td>28</td>\n",
       "      <td>0.201016</td>\n",
       "      <td>0.924833</td>\n",
       "      <td>0.349341</td>\n",
       "      <td>0.8849</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.097075</td>\n",
       "      <td>423.180332</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>33</td>\n",
       "      <td>29</td>\n",
       "      <td>0.197881</td>\n",
       "      <td>0.926067</td>\n",
       "      <td>0.346373</td>\n",
       "      <td>0.8844</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.134151</td>\n",
       "      <td>438.399485</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>0.195716</td>\n",
       "      <td>0.927733</td>\n",
       "      <td>0.348930</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>15.192289</td>\n",
       "      <td>453.678776</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>0.191416</td>\n",
       "      <td>0.928767</td>\n",
       "      <td>0.355509</td>\n",
       "      <td>0.8843</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.106269</td>\n",
       "      <td>468.865045</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>0.189186</td>\n",
       "      <td>0.928867</td>\n",
       "      <td>0.366553</td>\n",
       "      <td>0.8830</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>15.311535</td>\n",
       "      <td>484.268580</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0.186174</td>\n",
       "      <td>0.929983</td>\n",
       "      <td>0.358809</td>\n",
       "      <td>0.8858</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.208496</td>\n",
       "      <td>499.566074</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>0.183178</td>\n",
       "      <td>0.931750</td>\n",
       "      <td>0.369928</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.112010</td>\n",
       "      <td>514.764082</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>0.179340</td>\n",
       "      <td>0.933150</td>\n",
       "      <td>0.366526</td>\n",
       "      <td>0.8820</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.135042</td>\n",
       "      <td>529.979125</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "      <td>0.178017</td>\n",
       "      <td>0.933033</td>\n",
       "      <td>0.362995</td>\n",
       "      <td>0.8831</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>15.111716</td>\n",
       "      <td>545.177842</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "      <td>0.175730</td>\n",
       "      <td>0.933867</td>\n",
       "      <td>0.364469</td>\n",
       "      <td>0.8820</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.130044</td>\n",
       "      <td>560.394398</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>33</td>\n",
       "      <td>38</td>\n",
       "      <td>0.172063</td>\n",
       "      <td>0.935417</td>\n",
       "      <td>0.373480</td>\n",
       "      <td>0.8816</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>15.165372</td>\n",
       "      <td>575.637770</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "      <td>0.169525</td>\n",
       "      <td>0.936700</td>\n",
       "      <td>0.373732</td>\n",
       "      <td>0.8827</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.059004</td>\n",
       "      <td>590.778774</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>0.167190</td>\n",
       "      <td>0.937633</td>\n",
       "      <td>0.376416</td>\n",
       "      <td>0.8823</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.295667</td>\n",
       "      <td>606.154442</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>33</td>\n",
       "      <td>41</td>\n",
       "      <td>0.164295</td>\n",
       "      <td>0.938950</td>\n",
       "      <td>0.381927</td>\n",
       "      <td>0.8837</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>15.144363</td>\n",
       "      <td>621.391804</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>33</td>\n",
       "      <td>42</td>\n",
       "      <td>0.162093</td>\n",
       "      <td>0.939817</td>\n",
       "      <td>0.401577</td>\n",
       "      <td>0.8792</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.042545</td>\n",
       "      <td>636.522350</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "      <td>0.162129</td>\n",
       "      <td>0.939283</td>\n",
       "      <td>0.394500</td>\n",
       "      <td>0.8825</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>15.069653</td>\n",
       "      <td>651.682006</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>33</td>\n",
       "      <td>44</td>\n",
       "      <td>0.159087</td>\n",
       "      <td>0.940717</td>\n",
       "      <td>0.391056</td>\n",
       "      <td>0.8817</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.214040</td>\n",
       "      <td>666.976046</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>33</td>\n",
       "      <td>45</td>\n",
       "      <td>0.157024</td>\n",
       "      <td>0.941450</td>\n",
       "      <td>0.419446</td>\n",
       "      <td>0.8807</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>15.196191</td>\n",
       "      <td>682.261238</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>33</td>\n",
       "      <td>46</td>\n",
       "      <td>0.155324</td>\n",
       "      <td>0.941900</td>\n",
       "      <td>0.405690</td>\n",
       "      <td>0.8839</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>15.326412</td>\n",
       "      <td>697.680651</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>33</td>\n",
       "      <td>47</td>\n",
       "      <td>0.151988</td>\n",
       "      <td>0.942733</td>\n",
       "      <td>0.416795</td>\n",
       "      <td>0.8833</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>15.469896</td>\n",
       "      <td>713.230547</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>33</td>\n",
       "      <td>48</td>\n",
       "      <td>0.150609</td>\n",
       "      <td>0.943367</td>\n",
       "      <td>0.438298</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>15.797926</td>\n",
       "      <td>729.115473</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>33</td>\n",
       "      <td>49</td>\n",
       "      <td>0.149661</td>\n",
       "      <td>0.944100</td>\n",
       "      <td>0.442787</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>15.261145</td>\n",
       "      <td>744.462619</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>33</td>\n",
       "      <td>50</td>\n",
       "      <td>0.146356</td>\n",
       "      <td>0.944967</td>\n",
       "      <td>0.460571</td>\n",
       "      <td>0.8769</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>15.168581</td>\n",
       "      <td>759.713199</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      run  epoch      loss  accuracy  test_loss  test_accuracy  \\\n",
       "1600   33      1  0.799589  0.697000   0.628467         0.7633   \n",
       "1601   33      2  0.542897  0.793600   0.548165         0.8031   \n",
       "1602   33      3  0.468001  0.829500   0.480319         0.8253   \n",
       "1603   33      4  0.417899  0.848233   0.432517         0.8421   \n",
       "1604   33      5  0.383459  0.860333   0.400061         0.8542   \n",
       "1605   33      6  0.358139  0.868333   0.378867         0.8607   \n",
       "1606   33      7  0.339560  0.874933   0.369679         0.8635   \n",
       "1607   33      8  0.324624  0.880450   0.364067         0.8651   \n",
       "1608   33      9  0.312916  0.884750   0.357986         0.8675   \n",
       "1609   33     10  0.302602  0.888367   0.353483         0.8699   \n",
       "1610   33     11  0.293147  0.891617   0.346880         0.8734   \n",
       "1611   33     12  0.284506  0.894583   0.343232         0.8755   \n",
       "1612   33     13  0.277258  0.897233   0.334198         0.8791   \n",
       "1613   33     14  0.269657  0.899600   0.331246         0.8809   \n",
       "1614   33     15  0.262970  0.902000   0.326813         0.8837   \n",
       "1615   33     16  0.256555  0.904017   0.321746         0.8869   \n",
       "1616   33     17  0.250767  0.906850   0.321442         0.8869   \n",
       "1617   33     18  0.245078  0.908700   0.320948         0.8845   \n",
       "1618   33     19  0.239751  0.910500   0.319694         0.8841   \n",
       "1619   33     20  0.234728  0.912317   0.322230         0.8854   \n",
       "1620   33     21  0.230081  0.913650   0.319822         0.8856   \n",
       "1621   33     22  0.225892  0.915250   0.322645         0.8857   \n",
       "1622   33     23  0.221577  0.916733   0.323192         0.8848   \n",
       "1623   33     24  0.216738  0.918800   0.332345         0.8841   \n",
       "1624   33     25  0.212468  0.919967   0.334772         0.8845   \n",
       "1625   33     26  0.208588  0.921000   0.338064         0.8846   \n",
       "1626   33     27  0.204960  0.922400   0.342642         0.8849   \n",
       "1627   33     28  0.201016  0.924833   0.349341         0.8849   \n",
       "1628   33     29  0.197881  0.926067   0.346373         0.8844   \n",
       "1629   33     30  0.195716  0.927733   0.348930         0.8850   \n",
       "1630   33     31  0.191416  0.928767   0.355509         0.8843   \n",
       "1631   33     32  0.189186  0.928867   0.366553         0.8830   \n",
       "1632   33     33  0.186174  0.929983   0.358809         0.8858   \n",
       "1633   33     34  0.183178  0.931750   0.369928         0.8824   \n",
       "1634   33     35  0.179340  0.933150   0.366526         0.8820   \n",
       "1635   33     36  0.178017  0.933033   0.362995         0.8831   \n",
       "1636   33     37  0.175730  0.933867   0.364469         0.8820   \n",
       "1637   33     38  0.172063  0.935417   0.373480         0.8816   \n",
       "1638   33     39  0.169525  0.936700   0.373732         0.8827   \n",
       "1639   33     40  0.167190  0.937633   0.376416         0.8823   \n",
       "1640   33     41  0.164295  0.938950   0.381927         0.8837   \n",
       "1641   33     42  0.162093  0.939817   0.401577         0.8792   \n",
       "1642   33     43  0.162129  0.939283   0.394500         0.8825   \n",
       "1643   33     44  0.159087  0.940717   0.391056         0.8817   \n",
       "1644   33     45  0.157024  0.941450   0.419446         0.8807   \n",
       "1645   33     46  0.155324  0.941900   0.405690         0.8839   \n",
       "1646   33     47  0.151988  0.942733   0.416795         0.8833   \n",
       "1647   33     48  0.150609  0.943367   0.438298         0.8783   \n",
       "1648   33     49  0.149661  0.944100   0.442787         0.8811   \n",
       "1649   33     50  0.146356  0.944967   0.460571         0.8769   \n",
       "\n",
       "      test_score_time  epoch duration  run duration     lr  batch_size  \\\n",
       "1600         0.000035       14.372286     14.491285  0.001         100   \n",
       "1601         0.000035       14.827357     29.400642  0.001         100   \n",
       "1602         0.000035       14.847250     44.329893  0.001         100   \n",
       "1603         0.000037       14.823349     59.239241  0.001         100   \n",
       "1604         0.000044       14.913375     74.236618  0.001         100   \n",
       "1605         0.000036       15.018525     89.343145  0.001         100   \n",
       "1606         0.000036       14.866960    104.289104  0.001         100   \n",
       "1607         0.000037       15.038766    119.411872  0.001         100   \n",
       "1608         0.000036       14.934361    134.427235  0.001         100   \n",
       "1609         0.000038       15.069094    149.583329  0.001         100   \n",
       "1610         0.000037       14.937296    164.598628  0.001         100   \n",
       "1611         0.000036       14.970677    179.651307  0.001         100   \n",
       "1612         0.000038       15.047991    194.779299  0.001         100   \n",
       "1613         0.000043       15.142693    210.004992  0.001         100   \n",
       "1614         0.000038       14.931635    225.022628  0.001         100   \n",
       "1615         0.000037       15.214333    240.319961  0.001         100   \n",
       "1616         0.000037       15.047065    255.453025  0.001         100   \n",
       "1617         0.000037       15.174681    270.715704  0.001         100   \n",
       "1618         0.000037       15.059581    285.860286  0.001         100   \n",
       "1619         0.000038       15.083117    301.031404  0.001         100   \n",
       "1620         0.000037       15.473320    316.587726  0.001         100   \n",
       "1621         0.000046       15.263279    331.932008  0.001         100   \n",
       "1622         0.000042       15.136012    347.151020  0.001         100   \n",
       "1623         0.000037       15.240387    362.473406  0.001         100   \n",
       "1624         0.000037       15.076246    377.635655  0.001         100   \n",
       "1625         0.000037       15.142278    392.864934  0.001         100   \n",
       "1626         0.000042       15.041318    407.993253  0.001         100   \n",
       "1627         0.000037       15.097075    423.180332  0.001         100   \n",
       "1628         0.000037       15.134151    438.399485  0.001         100   \n",
       "1629         0.000038       15.192289    453.678776  0.001         100   \n",
       "1630         0.000037       15.106269    468.865045  0.001         100   \n",
       "1631         0.000038       15.311535    484.268580  0.001         100   \n",
       "1632         0.000037       15.208496    499.566074  0.001         100   \n",
       "1633         0.000037       15.112010    514.764082  0.001         100   \n",
       "1634         0.000037       15.135042    529.979125  0.001         100   \n",
       "1635         0.000038       15.111716    545.177842  0.001         100   \n",
       "1636         0.000037       15.130044    560.394398  0.001         100   \n",
       "1637         0.000039       15.165372    575.637770  0.001         100   \n",
       "1638         0.000037       15.059004    590.778774  0.001         100   \n",
       "1639         0.000037       15.295667    606.154442  0.001         100   \n",
       "1640         0.000044       15.144363    621.391804  0.001         100   \n",
       "1641         0.000037       15.042545    636.522350  0.001         100   \n",
       "1642         0.000038       15.069653    651.682006  0.001         100   \n",
       "1643         0.000037       15.214040    666.976046  0.001         100   \n",
       "1644         0.000041       15.196191    682.261238  0.001         100   \n",
       "1645         0.000038       15.326412    697.680651  0.001         100   \n",
       "1646         0.000042       15.469896    713.230547  0.001         100   \n",
       "1647         0.000037       15.797926    729.115473  0.001         100   \n",
       "1648         0.000040       15.261145    744.462619  0.001         100   \n",
       "1649         0.000038       15.168581    759.713199  0.001         100   \n",
       "\n",
       "      shuffle  weight_decay  \n",
       "1600     True           0.0  \n",
       "1601     True           0.0  \n",
       "1602     True           0.0  \n",
       "1603     True           0.0  \n",
       "1604     True           0.0  \n",
       "1605     True           0.0  \n",
       "1606     True           0.0  \n",
       "1607     True           0.0  \n",
       "1608     True           0.0  \n",
       "1609     True           0.0  \n",
       "1610     True           0.0  \n",
       "1611     True           0.0  \n",
       "1612     True           0.0  \n",
       "1613     True           0.0  \n",
       "1614     True           0.0  \n",
       "1615     True           0.0  \n",
       "1616     True           0.0  \n",
       "1617     True           0.0  \n",
       "1618     True           0.0  \n",
       "1619     True           0.0  \n",
       "1620     True           0.0  \n",
       "1621     True           0.0  \n",
       "1622     True           0.0  \n",
       "1623     True           0.0  \n",
       "1624     True           0.0  \n",
       "1625     True           0.0  \n",
       "1626     True           0.0  \n",
       "1627     True           0.0  \n",
       "1628     True           0.0  \n",
       "1629     True           0.0  \n",
       "1630     True           0.0  \n",
       "1631     True           0.0  \n",
       "1632     True           0.0  \n",
       "1633     True           0.0  \n",
       "1634     True           0.0  \n",
       "1635     True           0.0  \n",
       "1636     True           0.0  \n",
       "1637     True           0.0  \n",
       "1638     True           0.0  \n",
       "1639     True           0.0  \n",
       "1640     True           0.0  \n",
       "1641     True           0.0  \n",
       "1642     True           0.0  \n",
       "1643     True           0.0  \n",
       "1644     True           0.0  \n",
       "1645     True           0.0  \n",
       "1646     True           0.0  \n",
       "1647     True           0.0  \n",
       "1648     True           0.0  \n",
       "1649     True           0.0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[result_df['run']==best_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss regressed during the run!\n",
      "49 - 50\n",
      "test_loss regressed during the run!\n",
      "48 - 50\n",
      "accuracy regressed during the run!\n",
      "49 - 50\n",
      "test_accuracy regressed during the run!\n",
      "46 - 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('lr', 0.001),\n",
       "             ('batch_size', 500),\n",
       "             ('shuffle', True),\n",
       "             ('weight_decay', 0.0),\n",
       "             ('loss', 0.22064359498520603),\n",
       "             ('test_loss', 0.30747616291046104),\n",
       "             ('accuracy', 0.9195333333333331),\n",
       "             ('test_accuracy', 0.8963000000000001)])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_test = 41\n",
    "best_test_features = best_features(result_df[result_df['run']==best_test])\n",
    "best_test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_score_time</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1.156025</td>\n",
       "      <td>0.601367</td>\n",
       "      <td>0.742955</td>\n",
       "      <td>0.7146</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>13.410141</td>\n",
       "      <td>13.816140</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>0.660079</td>\n",
       "      <td>0.742550</td>\n",
       "      <td>0.643014</td>\n",
       "      <td>0.7553</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>13.329875</td>\n",
       "      <td>27.231015</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>0.585665</td>\n",
       "      <td>0.773633</td>\n",
       "      <td>0.572798</td>\n",
       "      <td>0.7842</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>13.349674</td>\n",
       "      <td>40.663690</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>0.536976</td>\n",
       "      <td>0.796617</td>\n",
       "      <td>0.527564</td>\n",
       "      <td>0.8059</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>13.358806</td>\n",
       "      <td>54.108496</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>0.497938</td>\n",
       "      <td>0.816367</td>\n",
       "      <td>0.491347</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>13.350804</td>\n",
       "      <td>67.544299</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>0.465214</td>\n",
       "      <td>0.831500</td>\n",
       "      <td>0.464123</td>\n",
       "      <td>0.8324</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>13.327790</td>\n",
       "      <td>80.955091</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>0.438088</td>\n",
       "      <td>0.842317</td>\n",
       "      <td>0.440701</td>\n",
       "      <td>0.8426</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>13.546607</td>\n",
       "      <td>94.583702</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>41</td>\n",
       "      <td>8</td>\n",
       "      <td>0.416723</td>\n",
       "      <td>0.849733</td>\n",
       "      <td>0.422666</td>\n",
       "      <td>0.8491</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>13.391113</td>\n",
       "      <td>108.058814</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>0.400208</td>\n",
       "      <td>0.856350</td>\n",
       "      <td>0.409260</td>\n",
       "      <td>0.8550</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>13.469896</td>\n",
       "      <td>121.613763</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>0.387057</td>\n",
       "      <td>0.860750</td>\n",
       "      <td>0.397019</td>\n",
       "      <td>0.8601</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>13.495353</td>\n",
       "      <td>135.190118</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>0.375111</td>\n",
       "      <td>0.864983</td>\n",
       "      <td>0.387434</td>\n",
       "      <td>0.8621</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>13.500254</td>\n",
       "      <td>148.774371</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>41</td>\n",
       "      <td>12</td>\n",
       "      <td>0.364664</td>\n",
       "      <td>0.868383</td>\n",
       "      <td>0.379817</td>\n",
       "      <td>0.8642</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>13.456027</td>\n",
       "      <td>162.305398</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>41</td>\n",
       "      <td>13</td>\n",
       "      <td>0.355306</td>\n",
       "      <td>0.871867</td>\n",
       "      <td>0.373279</td>\n",
       "      <td>0.8653</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>13.508920</td>\n",
       "      <td>175.898319</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>41</td>\n",
       "      <td>14</td>\n",
       "      <td>0.346362</td>\n",
       "      <td>0.876067</td>\n",
       "      <td>0.366763</td>\n",
       "      <td>0.8676</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>13.460338</td>\n",
       "      <td>189.442657</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>41</td>\n",
       "      <td>15</td>\n",
       "      <td>0.338796</td>\n",
       "      <td>0.879050</td>\n",
       "      <td>0.362014</td>\n",
       "      <td>0.8692</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>13.414560</td>\n",
       "      <td>202.942220</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "      <td>0.331696</td>\n",
       "      <td>0.880700</td>\n",
       "      <td>0.357238</td>\n",
       "      <td>0.8717</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>13.698534</td>\n",
       "      <td>216.720754</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>41</td>\n",
       "      <td>17</td>\n",
       "      <td>0.324874</td>\n",
       "      <td>0.882983</td>\n",
       "      <td>0.352148</td>\n",
       "      <td>0.8726</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>13.497973</td>\n",
       "      <td>230.296728</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>0.318696</td>\n",
       "      <td>0.884950</td>\n",
       "      <td>0.347572</td>\n",
       "      <td>0.8748</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>13.495603</td>\n",
       "      <td>243.871334</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>41</td>\n",
       "      <td>19</td>\n",
       "      <td>0.312316</td>\n",
       "      <td>0.887683</td>\n",
       "      <td>0.344936</td>\n",
       "      <td>0.8768</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>13.603090</td>\n",
       "      <td>257.558423</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "      <td>0.306858</td>\n",
       "      <td>0.889683</td>\n",
       "      <td>0.340969</td>\n",
       "      <td>0.8781</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>13.509761</td>\n",
       "      <td>271.151184</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>41</td>\n",
       "      <td>21</td>\n",
       "      <td>0.301892</td>\n",
       "      <td>0.891533</td>\n",
       "      <td>0.339184</td>\n",
       "      <td>0.8794</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>13.713853</td>\n",
       "      <td>284.943040</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>41</td>\n",
       "      <td>22</td>\n",
       "      <td>0.296735</td>\n",
       "      <td>0.893200</td>\n",
       "      <td>0.337454</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>13.637501</td>\n",
       "      <td>298.664600</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>41</td>\n",
       "      <td>23</td>\n",
       "      <td>0.292584</td>\n",
       "      <td>0.895133</td>\n",
       "      <td>0.334853</td>\n",
       "      <td>0.8807</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>13.528409</td>\n",
       "      <td>312.275519</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>0.288303</td>\n",
       "      <td>0.896417</td>\n",
       "      <td>0.332183</td>\n",
       "      <td>0.8809</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>13.500066</td>\n",
       "      <td>325.857584</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>41</td>\n",
       "      <td>25</td>\n",
       "      <td>0.284236</td>\n",
       "      <td>0.897217</td>\n",
       "      <td>0.331253</td>\n",
       "      <td>0.8816</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>13.581210</td>\n",
       "      <td>339.522793</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>41</td>\n",
       "      <td>26</td>\n",
       "      <td>0.280547</td>\n",
       "      <td>0.898450</td>\n",
       "      <td>0.329746</td>\n",
       "      <td>0.8819</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>13.684734</td>\n",
       "      <td>353.289527</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>41</td>\n",
       "      <td>27</td>\n",
       "      <td>0.277055</td>\n",
       "      <td>0.899867</td>\n",
       "      <td>0.330079</td>\n",
       "      <td>0.8822</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>13.683882</td>\n",
       "      <td>367.054410</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2027</th>\n",
       "      <td>41</td>\n",
       "      <td>28</td>\n",
       "      <td>0.273858</td>\n",
       "      <td>0.900800</td>\n",
       "      <td>0.329536</td>\n",
       "      <td>0.8816</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>13.632329</td>\n",
       "      <td>380.769739</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>41</td>\n",
       "      <td>29</td>\n",
       "      <td>0.270723</td>\n",
       "      <td>0.902133</td>\n",
       "      <td>0.328822</td>\n",
       "      <td>0.8836</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>13.620998</td>\n",
       "      <td>394.469738</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>0.267925</td>\n",
       "      <td>0.903200</td>\n",
       "      <td>0.327889</td>\n",
       "      <td>0.8841</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>13.565124</td>\n",
       "      <td>408.120861</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>41</td>\n",
       "      <td>31</td>\n",
       "      <td>0.264875</td>\n",
       "      <td>0.904400</td>\n",
       "      <td>0.329161</td>\n",
       "      <td>0.8842</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>13.592098</td>\n",
       "      <td>421.797962</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>41</td>\n",
       "      <td>32</td>\n",
       "      <td>0.261702</td>\n",
       "      <td>0.905167</td>\n",
       "      <td>0.327345</td>\n",
       "      <td>0.8837</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>13.641813</td>\n",
       "      <td>435.522779</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "      <td>0.258935</td>\n",
       "      <td>0.905900</td>\n",
       "      <td>0.325466</td>\n",
       "      <td>0.8840</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>13.543731</td>\n",
       "      <td>449.148510</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>41</td>\n",
       "      <td>34</td>\n",
       "      <td>0.256459</td>\n",
       "      <td>0.906850</td>\n",
       "      <td>0.324311</td>\n",
       "      <td>0.8853</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>13.540635</td>\n",
       "      <td>462.768144</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>41</td>\n",
       "      <td>35</td>\n",
       "      <td>0.254049</td>\n",
       "      <td>0.908133</td>\n",
       "      <td>0.323168</td>\n",
       "      <td>0.8861</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>13.540343</td>\n",
       "      <td>476.388486</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>41</td>\n",
       "      <td>36</td>\n",
       "      <td>0.251581</td>\n",
       "      <td>0.908733</td>\n",
       "      <td>0.321351</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>13.565909</td>\n",
       "      <td>490.034395</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>0.248980</td>\n",
       "      <td>0.909800</td>\n",
       "      <td>0.318163</td>\n",
       "      <td>0.8892</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>13.682635</td>\n",
       "      <td>503.800030</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "      <td>0.246564</td>\n",
       "      <td>0.910733</td>\n",
       "      <td>0.317520</td>\n",
       "      <td>0.8909</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>13.698179</td>\n",
       "      <td>517.580211</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>41</td>\n",
       "      <td>39</td>\n",
       "      <td>0.244172</td>\n",
       "      <td>0.911400</td>\n",
       "      <td>0.316062</td>\n",
       "      <td>0.8908</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>13.505088</td>\n",
       "      <td>531.167300</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>0.242137</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>0.314315</td>\n",
       "      <td>0.8921</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>13.520908</td>\n",
       "      <td>544.770211</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>0.239653</td>\n",
       "      <td>0.912767</td>\n",
       "      <td>0.312542</td>\n",
       "      <td>0.8931</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>13.656547</td>\n",
       "      <td>558.508759</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>0.237270</td>\n",
       "      <td>0.913900</td>\n",
       "      <td>0.310620</td>\n",
       "      <td>0.8928</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>13.529811</td>\n",
       "      <td>572.126569</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>0.235229</td>\n",
       "      <td>0.914217</td>\n",
       "      <td>0.310082</td>\n",
       "      <td>0.8925</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>13.819326</td>\n",
       "      <td>586.028895</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>41</td>\n",
       "      <td>44</td>\n",
       "      <td>0.232913</td>\n",
       "      <td>0.915100</td>\n",
       "      <td>0.309066</td>\n",
       "      <td>0.8938</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>13.639971</td>\n",
       "      <td>599.753865</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>41</td>\n",
       "      <td>45</td>\n",
       "      <td>0.230749</td>\n",
       "      <td>0.915950</td>\n",
       "      <td>0.308620</td>\n",
       "      <td>0.8954</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>13.618021</td>\n",
       "      <td>613.450886</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>41</td>\n",
       "      <td>46</td>\n",
       "      <td>0.229049</td>\n",
       "      <td>0.916433</td>\n",
       "      <td>0.308425</td>\n",
       "      <td>0.8952</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>13.733008</td>\n",
       "      <td>627.262895</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>41</td>\n",
       "      <td>47</td>\n",
       "      <td>0.226894</td>\n",
       "      <td>0.917517</td>\n",
       "      <td>0.308447</td>\n",
       "      <td>0.8963</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>13.635475</td>\n",
       "      <td>640.977371</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>41</td>\n",
       "      <td>48</td>\n",
       "      <td>0.225044</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.308563</td>\n",
       "      <td>0.8956</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>13.544364</td>\n",
       "      <td>654.603737</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>41</td>\n",
       "      <td>49</td>\n",
       "      <td>0.222643</td>\n",
       "      <td>0.918817</td>\n",
       "      <td>0.307476</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>13.580425</td>\n",
       "      <td>668.271161</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>41</td>\n",
       "      <td>50</td>\n",
       "      <td>0.220644</td>\n",
       "      <td>0.919533</td>\n",
       "      <td>0.308754</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>13.530177</td>\n",
       "      <td>681.883337</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      run  epoch      loss  accuracy  test_loss  test_accuracy  \\\n",
       "2000   41      1  1.156025  0.601367   0.742955         0.7146   \n",
       "2001   41      2  0.660079  0.742550   0.643014         0.7553   \n",
       "2002   41      3  0.585665  0.773633   0.572798         0.7842   \n",
       "2003   41      4  0.536976  0.796617   0.527564         0.8059   \n",
       "2004   41      5  0.497938  0.816367   0.491347         0.8214   \n",
       "2005   41      6  0.465214  0.831500   0.464123         0.8324   \n",
       "2006   41      7  0.438088  0.842317   0.440701         0.8426   \n",
       "2007   41      8  0.416723  0.849733   0.422666         0.8491   \n",
       "2008   41      9  0.400208  0.856350   0.409260         0.8550   \n",
       "2009   41     10  0.387057  0.860750   0.397019         0.8601   \n",
       "2010   41     11  0.375111  0.864983   0.387434         0.8621   \n",
       "2011   41     12  0.364664  0.868383   0.379817         0.8642   \n",
       "2012   41     13  0.355306  0.871867   0.373279         0.8653   \n",
       "2013   41     14  0.346362  0.876067   0.366763         0.8676   \n",
       "2014   41     15  0.338796  0.879050   0.362014         0.8692   \n",
       "2015   41     16  0.331696  0.880700   0.357238         0.8717   \n",
       "2016   41     17  0.324874  0.882983   0.352148         0.8726   \n",
       "2017   41     18  0.318696  0.884950   0.347572         0.8748   \n",
       "2018   41     19  0.312316  0.887683   0.344936         0.8768   \n",
       "2019   41     20  0.306858  0.889683   0.340969         0.8781   \n",
       "2020   41     21  0.301892  0.891533   0.339184         0.8794   \n",
       "2021   41     22  0.296735  0.893200   0.337454         0.8800   \n",
       "2022   41     23  0.292584  0.895133   0.334853         0.8807   \n",
       "2023   41     24  0.288303  0.896417   0.332183         0.8809   \n",
       "2024   41     25  0.284236  0.897217   0.331253         0.8816   \n",
       "2025   41     26  0.280547  0.898450   0.329746         0.8819   \n",
       "2026   41     27  0.277055  0.899867   0.330079         0.8822   \n",
       "2027   41     28  0.273858  0.900800   0.329536         0.8816   \n",
       "2028   41     29  0.270723  0.902133   0.328822         0.8836   \n",
       "2029   41     30  0.267925  0.903200   0.327889         0.8841   \n",
       "2030   41     31  0.264875  0.904400   0.329161         0.8842   \n",
       "2031   41     32  0.261702  0.905167   0.327345         0.8837   \n",
       "2032   41     33  0.258935  0.905900   0.325466         0.8840   \n",
       "2033   41     34  0.256459  0.906850   0.324311         0.8853   \n",
       "2034   41     35  0.254049  0.908133   0.323168         0.8861   \n",
       "2035   41     36  0.251581  0.908733   0.321351         0.8870   \n",
       "2036   41     37  0.248980  0.909800   0.318163         0.8892   \n",
       "2037   41     38  0.246564  0.910733   0.317520         0.8909   \n",
       "2038   41     39  0.244172  0.911400   0.316062         0.8908   \n",
       "2039   41     40  0.242137  0.912000   0.314315         0.8921   \n",
       "2040   41     41  0.239653  0.912767   0.312542         0.8931   \n",
       "2041   41     42  0.237270  0.913900   0.310620         0.8928   \n",
       "2042   41     43  0.235229  0.914217   0.310082         0.8925   \n",
       "2043   41     44  0.232913  0.915100   0.309066         0.8938   \n",
       "2044   41     45  0.230749  0.915950   0.308620         0.8954   \n",
       "2045   41     46  0.229049  0.916433   0.308425         0.8952   \n",
       "2046   41     47  0.226894  0.917517   0.308447         0.8963   \n",
       "2047   41     48  0.225044  0.918367   0.308563         0.8956   \n",
       "2048   41     49  0.222643  0.918817   0.307476         0.8955   \n",
       "2049   41     50  0.220644  0.919533   0.308754         0.8955   \n",
       "\n",
       "      test_score_time  epoch duration  run duration     lr  batch_size  \\\n",
       "2000         0.000038       13.410141     13.816140  0.001         500   \n",
       "2001         0.000035       13.329875     27.231015  0.001         500   \n",
       "2002         0.000035       13.349674     40.663690  0.001         500   \n",
       "2003         0.000035       13.358806     54.108496  0.001         500   \n",
       "2004         0.000037       13.350804     67.544299  0.001         500   \n",
       "2005         0.000035       13.327790     80.955091  0.001         500   \n",
       "2006         0.000036       13.546607     94.583702  0.001         500   \n",
       "2007         0.000035       13.391113    108.058814  0.001         500   \n",
       "2008         0.000036       13.469896    121.613763  0.001         500   \n",
       "2009         0.000044       13.495353    135.190118  0.001         500   \n",
       "2010         0.000036       13.500254    148.774371  0.001         500   \n",
       "2011         0.000036       13.456027    162.305398  0.001         500   \n",
       "2012         0.000038       13.508920    175.898319  0.001         500   \n",
       "2013         0.000035       13.460338    189.442657  0.001         500   \n",
       "2014         0.000036       13.414560    202.942220  0.001         500   \n",
       "2015         0.000036       13.698534    216.720754  0.001         500   \n",
       "2016         0.000036       13.497973    230.296728  0.001         500   \n",
       "2017         0.000036       13.495603    243.871334  0.001         500   \n",
       "2018         0.000037       13.603090    257.558423  0.001         500   \n",
       "2019         0.000036       13.509761    271.151184  0.001         500   \n",
       "2020         0.000037       13.713853    284.943040  0.001         500   \n",
       "2021         0.000048       13.637501    298.664600  0.001         500   \n",
       "2022         0.000038       13.528409    312.275519  0.001         500   \n",
       "2023         0.000036       13.500066    325.857584  0.001         500   \n",
       "2024         0.000038       13.581210    339.522793  0.001         500   \n",
       "2025         0.000036       13.684734    353.289527  0.001         500   \n",
       "2026         0.000045       13.683882    367.054410  0.001         500   \n",
       "2027         0.000036       13.632329    380.769739  0.001         500   \n",
       "2028         0.000036       13.620998    394.469738  0.001         500   \n",
       "2029         0.000037       13.565124    408.120861  0.001         500   \n",
       "2030         0.000037       13.592098    421.797962  0.001         500   \n",
       "2031         0.000044       13.641813    435.522779  0.001         500   \n",
       "2032         0.000037       13.543731    449.148510  0.001         500   \n",
       "2033         0.000036       13.540635    462.768144  0.001         500   \n",
       "2034         0.000036       13.540343    476.388486  0.001         500   \n",
       "2035         0.000036       13.565909    490.034395  0.001         500   \n",
       "2036         0.000037       13.682635    503.800030  0.001         500   \n",
       "2037         0.000037       13.698179    517.580211  0.001         500   \n",
       "2038         0.000037       13.505088    531.167300  0.001         500   \n",
       "2039         0.000037       13.520908    544.770211  0.001         500   \n",
       "2040         0.000037       13.656547    558.508759  0.001         500   \n",
       "2041         0.000037       13.529811    572.126569  0.001         500   \n",
       "2042         0.000037       13.819326    586.028895  0.001         500   \n",
       "2043         0.000037       13.639971    599.753865  0.001         500   \n",
       "2044         0.000041       13.618021    613.450886  0.001         500   \n",
       "2045         0.000037       13.733008    627.262895  0.001         500   \n",
       "2046         0.000043       13.635475    640.977371  0.001         500   \n",
       "2047         0.000037       13.544364    654.603737  0.001         500   \n",
       "2048         0.000037       13.580425    668.271161  0.001         500   \n",
       "2049         0.000037       13.530177    681.883337  0.001         500   \n",
       "\n",
       "      shuffle  weight_decay  \n",
       "2000     True           0.0  \n",
       "2001     True           0.0  \n",
       "2002     True           0.0  \n",
       "2003     True           0.0  \n",
       "2004     True           0.0  \n",
       "2005     True           0.0  \n",
       "2006     True           0.0  \n",
       "2007     True           0.0  \n",
       "2008     True           0.0  \n",
       "2009     True           0.0  \n",
       "2010     True           0.0  \n",
       "2011     True           0.0  \n",
       "2012     True           0.0  \n",
       "2013     True           0.0  \n",
       "2014     True           0.0  \n",
       "2015     True           0.0  \n",
       "2016     True           0.0  \n",
       "2017     True           0.0  \n",
       "2018     True           0.0  \n",
       "2019     True           0.0  \n",
       "2020     True           0.0  \n",
       "2021     True           0.0  \n",
       "2022     True           0.0  \n",
       "2023     True           0.0  \n",
       "2024     True           0.0  \n",
       "2025     True           0.0  \n",
       "2026     True           0.0  \n",
       "2027     True           0.0  \n",
       "2028     True           0.0  \n",
       "2029     True           0.0  \n",
       "2030     True           0.0  \n",
       "2031     True           0.0  \n",
       "2032     True           0.0  \n",
       "2033     True           0.0  \n",
       "2034     True           0.0  \n",
       "2035     True           0.0  \n",
       "2036     True           0.0  \n",
       "2037     True           0.0  \n",
       "2038     True           0.0  \n",
       "2039     True           0.0  \n",
       "2040     True           0.0  \n",
       "2041     True           0.0  \n",
       "2042     True           0.0  \n",
       "2043     True           0.0  \n",
       "2044     True           0.0  \n",
       "2045     True           0.0  \n",
       "2046     True           0.0  \n",
       "2047     True           0.0  \n",
       "2048     True           0.0  \n",
       "2049     True           0.0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[result_df['run']==best_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameter testing conclusions:\n",
    "- Lower learning rate is better overall\n",
    "- Smaller batch is better, but can be improved\n",
    "- Need to make sure that the training set isn't becoming overfit on small batches\n",
    "- Improvements in train accuracy != improvements in test accuracy and generalization  \n",
    "\n",
    "### Next steps: Take the previous learning and apply similar training conditions to a longer epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some hyperparameter tuning\n",
    "# put all hyper params into a OrderedDict, easily expandable\n",
    "params = OrderedDict(\n",
    "    lr = [ .001],\n",
    "    batch_size = [100, 250, 500],\n",
    "    shuffle = [True],\n",
    "    weight_decay = [0]\n",
    ")\n",
    "epochs = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_score_time</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.790605</td>\n",
       "      <td>0.697617</td>\n",
       "      <td>0.606031</td>\n",
       "      <td>0.7704</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>17.145000</td>\n",
       "      <td>17.284993</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.518677</td>\n",
       "      <td>0.805767</td>\n",
       "      <td>0.510038</td>\n",
       "      <td>0.8094</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>17.385999</td>\n",
       "      <td>34.732993</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.452223</td>\n",
       "      <td>0.833617</td>\n",
       "      <td>0.466107</td>\n",
       "      <td>0.8270</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>16.850999</td>\n",
       "      <td>51.641993</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.411550</td>\n",
       "      <td>0.849233</td>\n",
       "      <td>0.420051</td>\n",
       "      <td>0.8433</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>16.514999</td>\n",
       "      <td>68.219992</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.380166</td>\n",
       "      <td>0.860017</td>\n",
       "      <td>0.391371</td>\n",
       "      <td>0.8569</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>16.981999</td>\n",
       "      <td>85.262993</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>0.160363</td>\n",
       "      <td>0.940683</td>\n",
       "      <td>0.349402</td>\n",
       "      <td>0.8921</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>17.901916</td>\n",
       "      <td>1512.258783</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "      <td>0.159678</td>\n",
       "      <td>0.941350</td>\n",
       "      <td>0.345761</td>\n",
       "      <td>0.8921</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>19.274727</td>\n",
       "      <td>1531.608511</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>3</td>\n",
       "      <td>98</td>\n",
       "      <td>0.158716</td>\n",
       "      <td>0.942250</td>\n",
       "      <td>0.347496</td>\n",
       "      <td>0.8922</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>18.176013</td>\n",
       "      <td>1549.881505</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>0.158371</td>\n",
       "      <td>0.941917</td>\n",
       "      <td>0.346041</td>\n",
       "      <td>0.8924</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>17.276356</td>\n",
       "      <td>1567.237863</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.159123</td>\n",
       "      <td>0.940817</td>\n",
       "      <td>0.347214</td>\n",
       "      <td>0.8920</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>16.820200</td>\n",
       "      <td>1584.144063</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     run  epoch      loss  accuracy  test_loss  test_accuracy  \\\n",
       "0      1      1  0.790605  0.697617   0.606031         0.7704   \n",
       "1      1      2  0.518677  0.805767   0.510038         0.8094   \n",
       "2      1      3  0.452223  0.833617   0.466107         0.8270   \n",
       "3      1      4  0.411550  0.849233   0.420051         0.8433   \n",
       "4      1      5  0.380166  0.860017   0.391371         0.8569   \n",
       "..   ...    ...       ...       ...        ...            ...   \n",
       "295    3     96  0.160363  0.940683   0.349402         0.8921   \n",
       "296    3     97  0.159678  0.941350   0.345761         0.8921   \n",
       "297    3     98  0.158716  0.942250   0.347496         0.8922   \n",
       "298    3     99  0.158371  0.941917   0.346041         0.8924   \n",
       "299    3    100  0.159123  0.940817   0.347214         0.8920   \n",
       "\n",
       "     test_score_time  epoch duration  run duration     lr  batch_size  \\\n",
       "0           0.000045       17.145000     17.284993  0.001         100   \n",
       "1           0.000037       17.385999     34.732993  0.001         100   \n",
       "2           0.000039       16.850999     51.641993  0.001         100   \n",
       "3           0.000038       16.514999     68.219992  0.001         100   \n",
       "4           0.000039       16.981999     85.262993  0.001         100   \n",
       "..               ...             ...           ...    ...         ...   \n",
       "295         0.000053       17.901916   1512.258783  0.001         500   \n",
       "296         0.000056       19.274727   1531.608511  0.001         500   \n",
       "297         0.000070       18.176013   1549.881505  0.001         500   \n",
       "298         0.000048       17.276356   1567.237863  0.001         500   \n",
       "299         0.000057       16.820200   1584.144063  0.001         500   \n",
       "\n",
       "     shuffle  weight_decay  \n",
       "0       True             0  \n",
       "1       True             0  \n",
       "2       True             0  \n",
       "3       True             0  \n",
       "4       True             0  \n",
       "..       ...           ...  \n",
       "295     True             0  \n",
       "296     True             0  \n",
       "297     True             0  \n",
       "298     True             0  \n",
       "299     True             0  \n",
       "\n",
       "[300 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model to ./saved_models/model-3.pth\n"
     ]
    }
   ],
   "source": [
    "# This code is all from the tutorial, but I can probably improve on it by getting the runs to happen in parallel - test that\n",
    "m = RunManager()\n",
    "\n",
    "print(f\"Total number of runs: {len(RunBuilder.get_runs(params))}\")\n",
    "print(f\"Total number of epochs: {epochs*len(RunBuilder.get_runs(params))}\")\n",
    "print(f\"Time required @ 15s / epoch: {15*epochs*len(RunBuilder.get_runs(params))} seconds, {(1/240)*epochs*len(RunBuilder.get_runs(params))} hours\")\n",
    "\n",
    "# get all runs from params using RunBuilder class\n",
    "for run in RunBuilder.get_runs(params):\n",
    "\n",
    "    # if params changes, following line of code should reflect the changes too\n",
    "    network = Network()\n",
    "    loader = torch.utils.data.DataLoader(train_set, batch_size = run.batch_size)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=run.lr, weight_decay = run.weight_decay)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size = len(test_set))\n",
    "    \n",
    "    m.begin_run(run, network, loader)\n",
    "    for epoch in range(epochs):\n",
    "      \n",
    "      m.begin_epoch()\n",
    "    \n",
    "      for batch in loader:\n",
    "        \n",
    "        images = batch[0]\n",
    "        labels = batch[1]\n",
    "        preds = network(images)\n",
    "        loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        m.track_loss(loss)\n",
    "        m.track_num_correct(preds, labels)\n",
    "      \n",
    "      for batch in test_loader:\n",
    "        test_images = batch[0]\n",
    "        test_labels = batch[1]\n",
    "        score_start_time = time.time()\n",
    "        test_preds = network(test_images)\n",
    "        score_end_time = time.time()\n",
    "        test_loss = F.cross_entropy(test_preds, test_labels)\n",
    "        \n",
    "        m.track_loss_test(test_loss)\n",
    "        m.track_num_correct_test(test_preds, test_labels)\n",
    "        m.track_score_time_test(score_start_time, score_end_time)\n",
    "        \n",
    "    \n",
    "      m.end_epoch()\n",
    "    m.end_run()\n",
    "\n",
    "# when all runs are done, save results to files\n",
    "m.save('results_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_score_time</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>weight_decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.085840</td>\n",
       "      <td>0.966467</td>\n",
       "      <td>0.728042</td>\n",
       "      <td>0.8790</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>16.819000</td>\n",
       "      <td>1757.332458</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.116327</td>\n",
       "      <td>0.955617</td>\n",
       "      <td>0.475596</td>\n",
       "      <td>0.8833</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>19.122095</td>\n",
       "      <td>1507.775643</td>\n",
       "      <td>0.001</td>\n",
       "      <td>250</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.159123</td>\n",
       "      <td>0.940817</td>\n",
       "      <td>0.347214</td>\n",
       "      <td>0.8920</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>16.820200</td>\n",
       "      <td>1584.144063</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     run  epoch      loss  accuracy  test_loss  test_accuracy  \\\n",
       "99     1    100  0.085840  0.966467   0.728042         0.8790   \n",
       "199    2    100  0.116327  0.955617   0.475596         0.8833   \n",
       "299    3    100  0.159123  0.940817   0.347214         0.8920   \n",
       "\n",
       "     test_score_time  epoch duration  run duration     lr  batch_size  \\\n",
       "99          0.000037       16.819000   1757.332458  0.001         100   \n",
       "199         0.000042       19.122095   1507.775643  0.001         250   \n",
       "299         0.000057       16.820200   1584.144063  0.001         500   \n",
       "\n",
       "     shuffle  weight_decay  \n",
       "99      True             0  \n",
       "199     True             0  \n",
       "299     True             0  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.read_json('results_final.json')\n",
    "final_df[final_df['epoch']==100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEsting the load - this will actually be in the ap after this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network()\n",
    "model.load_state_dict(torch.load('saved_models/model-1.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
      "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(Network())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f-c",
   "language": "python",
   "name": "f-c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
